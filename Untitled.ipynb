{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python Imports\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import SVD, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore, KNNBaseline\n",
    "from surprise.prediction_algorithms.matrix_factorization import NMF\n",
    "from pandas.io.json import json_normalize\n",
    "from pymongo import MongoClient\n",
    "from collections import defaultdict\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ids(ids_in_csv):\n",
    "    return pd.to_numeric(ids_in_csv, errors='coerce').astype('int64')\n",
    "\n",
    "def convert_to_float(ids_in_csv):\n",
    "    return pd.to_numeric(ids_in_csv, errors='coerce').astype('float64')\n",
    "\n",
    "def to_json(csv_entry):\n",
    "    return json.loads(re.sub('\\'', '\"', csv_entry))\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=200):\n",
    "    '''COPIED FROM SUPRISE API\n",
    "    Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_movie_name(movie_id):\n",
    "    return ratings_with_movie_names[ratings_with_movie_names.id == movie_id]['title'].iloc[0]\n",
    "\n",
    "\n",
    "def print_user_prediction(userId, predictions_dict, meta_df):\n",
    "    users_viewed_movies = ratings_with_movie_names[ratings_with_movie_names['userId'] == userId][\n",
    "        ['rating', 'original_title']]\n",
    "    print(f'User {userId} has viewed the following movies:\\n')\n",
    "\n",
    "    for row in users_viewed_movies.itertuples():\n",
    "        rating = row[1]\n",
    "        original_title = row[2]\n",
    "        print(f'\\t{original_title}, Rating: {rating}')\n",
    "\n",
    "    print(f'\\nThe following movies are recommended for User {userId}\\n')\n",
    "    recommended_movies = [get_movie_name(mov_id[0], meta_df) for mov_id in predictions_dict[userId]]\n",
    "\n",
    "    for movie in recommended_movies:\n",
    "        print(f'\\t{movie}')\n",
    "\n",
    "def get_movie_name(movie_id, movie_meta_df):\n",
    "    return movie_meta_df[movie_meta_df.id == movie_id]['title'].iloc[0]\n",
    "\n",
    "def get_movie_id(title, movie_meta_df):\n",
    "    return movie_meta_df[movie_meta_df.title == title]['id'].iloc[0]\n",
    "\n",
    "\n",
    "def get_all_movies_in_cluster(cluster_number, cluster_dict, meta_df):\n",
    "    movies = cluster_dict[cluster_number]\n",
    "    return [get_movie_name(mov, meta_df) for mov in movies]\n",
    "\n",
    "####\n",
    "\n",
    "# cluster_distribution = [len(movies) for (clust, movies) in movie_summaries_clustered.items()]\n",
    "\n",
    "def get_cluster_number(movie, cluster_zip):\n",
    "    for cluster, movie_id in cluster_zip:\n",
    "\n",
    "        if movie_id == movie:\n",
    "            return cluster\n",
    "\n",
    "    raise Exception('Movie not found in cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df1 = pd.read_csv('the-movies-dataset/movies_metadata.csv'\n",
    "                                 , converters={ 'id': lambda x: convert_ids(x)\n",
    "                                               , 'imdb_id': lambda x: convert_ids(x)\n",
    "                                               ,'popularity': lambda x: convert_to_float(x)\n",
    "                                               ,'genres': lambda x: to_json(x)}\n",
    "                                 , usecols=['id', 'original_title'\n",
    "                                                , 'genres' #'homepage'\n",
    "                                                , 'overview', 'popularity', 'poster_path'\n",
    "                                                , 'release_date', 'revenue', 'runtime'\n",
    "                                                , 'spoken_languages', 'title'\n",
    "                                                , 'vote_average', 'vote_count']\n",
    "                                , dtype={'populariy': np.float64}\n",
    "                                , parse_dates=True)\n",
    "\n",
    "\n",
    "movies_lookup_df = pd.read_csv('the-movies-dataset/movies_metadata.csv'\n",
    "                        , converters={'id': lambda x: convert_ids(x), 'imdb_id': lambda x: convert_ids(x)}\n",
    "                       ,usecols=['id', 'title'])\n",
    "\n",
    "#####################################\n",
    "##SVD DATA SET\n",
    "movies_df = pd.read_csv('the-movies-dataset/movies_metadata.csv'\n",
    "                        , converters={'id': lambda x: convert_ids(x), 'imdb_id': lambda x: convert_ids(x)}\n",
    "                       ,usecols=['id', 'original_title', 'belongs_to_collection'\n",
    "                                 , 'budget', 'genres', 'homepage'\n",
    "                                 ,'imdb_id', 'overview', 'popularity', 'poster_path'\n",
    "                                 , 'production_companies','release_date', 'revenue', 'runtime',\n",
    "                                 'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
    "                                 'vote_average', 'vote_count'])\n",
    "#####################################\n",
    "\n",
    "ratings_df = pd.read_csv('the-movies-dataset/ratings_small.csv')\n",
    "\n",
    "\n",
    "\n",
    "content_filter_df = pd.read_pickle('content_filter_df.pkl')\n",
    "content_filter_df = content_filter_df[['id',\n",
    " 'popularity',\n",
    " #'release_date',\n",
    " 'vote_average',\n",
    " 'release_year',\n",
    " 0,1,2,3,4,5, 6, 7, 8,9,10,11,12,13,14,15,16,17,18,19]]\n",
    "content_filter_df = content_filter_df.dropna()\n",
    "\n",
    "idx = pd.Index(content_filter_df['id'])\n",
    "idx\n",
    "content_filter_df.index = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###May need Fuzzy matching, but for now:\n",
    "movies_df = movies_df[movies_df.spoken_languages == \"\"\"[{'iso_639_1': 'en', 'name': 'English'}]\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_with_movie_names = ratings_df.merge(movies_df[['id', 'original_title']], how='left', left_on='movieId', right_on='id')\n",
    "ratings_with_movie_names = ratings_with_movie_names[ratings_with_movie_names.original_title.isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(ratings_with_movie_names[['userId', 'movieId', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(verbose=True)\n",
    "algo.fit(trainset)\n",
    "\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)\n",
    "### Tune this value to get fewer results faster, but less options to choose from\n",
    "top_n = get_top_n(predictions)\n",
    "\n",
    "\n",
    "predicted_movies_by_name = defaultdict(list)\n",
    "\n",
    "### This builds the dictionary of predicted movies for all users\n",
    "for key, value in top_n.items():\n",
    "    predicted_movies_by_name[key] = [get_movie_name(mov_id[0], movies_metadata_df1) for mov_id in value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "UserFavoriteRating = namedtuple('UserFavoriteRating', ['title', 'rating'])\n",
    "\n",
    "def users_top_n_movies(n, userId, predictions_dict, meta_df):\n",
    "    users_viewed_movies = ratings_with_movie_names[ratings_with_movie_names['userId'] == userId][['rating', 'original_title']]\n",
    "    \n",
    "    viewed_movies = []\n",
    "\n",
    "    for row in users_viewed_movies.itertuples():\n",
    "        rating = row[1]\n",
    "        original_title = row[2]\n",
    "        film = UserFavoriteRating(original_title, rating)\n",
    "        viewed_movies.append(film)\n",
    "    \n",
    "    sorted(viewed_movies, key=lambda film: film[1])\n",
    "    \n",
    "    return viewed_movies[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET A USERS TOP RATED MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_top_n_movies(5, 321, predicted_movies_by_name, movies_metadata_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this point, you should have user personas to get a pool of movies to choose from, not simply pre-made users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_user_prediction(321, top_n, movies_metadata_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_user_prediction(47, top_n, movies_metadata_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_user_prediction(47, top_n, movies_metadata_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserFavoriteRating = namedtuple('UserFavoriteRating', ['title', 'rating'])\n",
    "def collab_filter_recommendations(user, top_ns, movie_meta_df):\n",
    "    \n",
    "    predictions = top_ns[user]\n",
    "    \n",
    "    return [UserFavoriteRating(get_movie_name(pred[0], movie_meta_df), pred[1]) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_filter_recommendations(47, top_n, movies_metadata_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTENT FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df = pd.read_csv('the-movies-dataset/movies_metadata.csv'\n",
    "                                 , converters={ 'id': lambda x: convert_ids(x)\n",
    "                                               , 'imdb_id': lambda x: convert_ids(x)\n",
    "                                               ,'popularity': lambda x: convert_to_float(x)\n",
    "                                               ,'genres': lambda x: to_json(x)}\n",
    "                                 , usecols=['id', 'original_title'\n",
    "                                                , 'genres' #'homepage'\n",
    "                                                , 'overview', 'popularity', 'poster_path'\n",
    "                                                , 'release_date', 'revenue', 'runtime'\n",
    "                                                , 'spoken_languages', 'title'\n",
    "                                                , 'vote_average', 'vote_count']\n",
    "                                , dtype={'populariy': np.float64}\n",
    "                                , parse_dates=True)\n",
    "movies_metadata_df = movies_metadata_df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, tfidf_matrix):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = movies_df[title]\n",
    "    cosine_sim = linear_kernel(tfidf_matrix[idx], tfidf_matrix)\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[0:21]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    #print(idx, title , movies_metadata_df['title'].iloc[idx],movies_metadata_df['genres'].iloc[idx])\n",
    "    return movies_metadata_df['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keywords and credits\n",
    "credits = pd.read_csv('the-movies-dataset/credits.csv')\n",
    "keywords = pd.read_csv('the-movies-dataset/keywords.csv')\n",
    "\n",
    "credits = credits.drop_duplicates(subset=['id'])\n",
    "keywords = keywords.drop_duplicates(subset=['id'])\n",
    "\n",
    "# Convert IDs to int. Required for merging\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "movies_metadata_df['id'] = movies_metadata_df['id'].astype('int')\n",
    "\n",
    "# Merge keywords and credits into your main metadata dataframe\n",
    "movies_metadata_df = credits.merge(movies_metadata_df, on='id')\n",
    "movies_metadata_df = movies_metadata_df.merge(keywords, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.Series(movies_metadata_df.index, index=movies_metadata_df['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    movies_metadata_df[feature] = movies_metadata_df[feature].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "\n",
    "# Returns the list top 3 elements or entire list; whichever is more.\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
    "        if len(names) > 3:\n",
    "            names = names[:3]\n",
    "        return names\n",
    "\n",
    "    #Return empty list in case of missing/malformed data\n",
    "    return []\n",
    "\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''\n",
    "        \n",
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new director, cast, genres and keywords features that are in a suitable form.\n",
    "movies_metadata_df['director'] = movies_metadata_df['crew'].apply(get_director)\n",
    "\n",
    "features = ['cast', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    movies_metadata_df[feature] = movies_metadata_df[feature].apply(get_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clean_data function to your features.\n",
    "features = ['cast', 'keywords', 'director', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    movies_metadata_df[feature] = movies_metadata_df[feature].apply(clean_data)\n",
    "\n",
    "# Create a new soup feature\n",
    "movies_metadata_df['soup'] = movies_metadata_df.apply(create_soup, axis=1)\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(movies_metadata_df['soup'])\n",
    "#count_matrix\n",
    "cosine_sim = linear_kernel(count_matrix[0], count_matrix)\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_recommendations('Sherlock Holmes',count_matrix))\n",
    "print_user_prediction(47, top_n, movies_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_number = 321\n",
    "predictions_dict = predicted_movies_by_name\n",
    "get_graph_on = users_top_n_movies(5, user_number, predictions_dict, movies_metadata_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_graph_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neo4j-driver==v1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neomodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://localhost:8888\"\n",
    "driver = GraphDatabase.driver(uri, auth=('neo4j', 'n;slr#!21'))\n",
    "\n",
    "\n",
    "def get_count_first_degree_films_of(tx, title):\n",
    "    for record in tx.run(\"MATCH (origin:MOVIE)-[:APPEARED_IN]-(actor)-[:APPEARED_IN]-(first_movie:MOVIE)\"\n",
    "                         \"WHERE origin.title = {title} \"\n",
    "                         \"RETURN count(*)\", title=title):\n",
    "        print(record[0])\n",
    "        \n",
    "def get_first_degree_films_of(tx, title):\n",
    "    nodes = []\n",
    "    \n",
    "    for record in tx.run(\"MATCH (origin:MOVIE)-[:APPEARED_IN]-(actor)-[:APPEARED_IN]-(first_movie:MOVIE)\"\n",
    "                         \"WHERE origin.title = {title} \"\n",
    "                         \"RETURN first_movie\", title=title):\n",
    "        \n",
    "        nodes.append(record.data())\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "first_degree_away = None\n",
    "with driver.session() as session:\n",
    "    first_degree_away = session.read_transaction(get_first_degree_films_of, 'Sleepless in Seattle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_degree_away[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(first_degree_away[0]['first_movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_degree_away[0]['first_movie'].get('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_degree_away[0]['first_movie'].get('movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphMember = namedtuple('GraphMember', ['title', 'movie_id'])\n",
    "\n",
    "def neo4j_results_to_tuples(results):\n",
    "    return [GraphMember(node['first_movie'].get('title'), node['first_movie'].get('movie_id')) for node in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybridization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_filtered_to_movie_rec_tuples(sleepless_filtered_recs, 858, movies_lookup_df)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_results_to_tuples(first_degree_away)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_top_n_movies(5, 321, predicted_movies_by_name, movies_metadata_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a test with a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(users_top_n_movies(200, 321, predicted_movies_by_name, movies_metadata_df1), key=lambda k: k[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_three_favs(user_id):\n",
    "    \n",
    "    favorite_seen_movie_array = users_top_n_movies(200, user_id, predicted_movies_by_name, movies_metadata_df1)\n",
    "    sorted_seen_movies = sorted(favorite_seen_movie_array, key=lambda k: k[1], reverse=True)\n",
    "    return sorted_seen_movies[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_three_favs(321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collab Filter List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_filtered_movies = sorted(collab_filter_recommendations(47, top_n, movies_metadata_df1), key=lambda k: k[1], reverse=True)\n",
    "collab_filtered_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get_movie_id('The Endless Summer', movies_metadata_df1)\n",
    "# content_filtered_tups = top_n_closest_content_filtered(50, 321, content_filter_df)\n",
    "# content_filtered_tups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_filtered_tups = get_recommendations('Sherlock Holmes',count_matrix)\n",
    "content_filtered_tups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_list = get_top_three_favs(321)\n",
    "movie_names = [movie[0] for movie in favorite_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_movies(list_favorite_movies):\n",
    "    return list_connected_movies\n",
    "\n",
    "first_degree_away = []\n",
    "with driver.session() as session:\n",
    "    \n",
    "    for movie in movie_names:\n",
    "        first_degree_away_films = session.read_transaction(get_first_degree_films_of, movie)\n",
    "        film_tups = neo4j_results_to_tuples(first_degree_away_films)\n",
    "        first_degree_away.extend(film_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_degree_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_id_content_filter = set({movie[1] for movie in first_degree_away})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_name_collab_filter = set({movie[0] for movie in first_degree_away})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_id_set = set(movie[0] for movie in content_filtered_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_movie_name_set = set(movie[0] for movie in collab_filtered_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_name_collab_filter & collab_movie_name_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_id_set & graph_id_content_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_movie_name(550, movies_metadata_df1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
